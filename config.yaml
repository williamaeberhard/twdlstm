# Configuration for twdlstm v0.5.3

path_data: '/mydata/forestcast/william/WP3/DataProcessed'
path_outputdir: '/mydata/forestcast/william/WP3/LSTM_runs/outputs'
path_checkpointdir: '/mydata/forestcast/william/WP3/LSTM_runs/checkpoints'

prefixoutput: '00' #

tstoy: '05' # '04' for tstoy04, '05' for tstoy05, etc.

# * tstoy05 series (01-20) by species (unique by site)
#   - Picea abies (5):
#     "05", "07", "08", "15", "19"
#   - Fagus sylvatica (7):
#     "01", "06", "11", "13", "17", "18", "20"
#   - Quercus petraea (2):
#     "02", "12"
#   - Pinus sylvestris (3):
#     "09", "14", "16"
#   - Carpinus betulus (1):
#     "03"
#   - Corylus avellana (1):
#     "04"
#   - Pseudotsuga menziesii (1):
#     "10"
# * tstoy05 series that are homogeneous enough by species:
#   - Picea abies (4):
#     "05", "07", "15", "19"
#     after removing
#     "08"
#   - Fagus sylvatica (5):
#     "06", "11", "13", "18", "20"
#     after removing:
#     "01", "17"
#   - Quercus petraea (2):
#     "02", "12"
#   - Pinus sylvestris (2):
#     "09", "14"
#     after removing:
#     "16"

# series: ["10", "28", "35", "36", "37", "38", "39"] # full
# ^ Picea abies prop samp at 3 selected sites (among 4 after excl 1 series)
# series_trva: ["10", "28"]
# series_te: ["11", "12", "16", "17", "29", "40", "41"] # tstoy04 full
# series_te: ["11", "12", "16"]
series_trva: ["05", "07", "15"] # tstoy05 all Picea abies tr
series_te: ["19"] # tstoy05 all Picea abies te
# ^ trva (tr and va) used by train.py, te only used by test.py

# date_t0: '2021-01-01' # assuming time points are daily
# ind_t0: 366 # 2021-01-01
date_t0: '2020-01-01' # assuming time points are daily
# nT_tr: 366 # size of tr set (time points), starts from date_t0
# nT_va: 100 # size of va set, starts right after the nT_tr time points
nT: 20 # subset size (time points), split in batches, starts from date_t0
prop_va: 0.2 # proportion of data batches held-out for va set
srs_seed: 1234 # seed for simple random sampling for va subset

batch_len: 5 # length of batches, both for tr and va
# loss_hor: 1 # nb values at end of each batch contribute to tr/va loss
# ^ v0.4.2: deprecated, hard-coded to 1, i.e. only last obs of batch contributes

covvec: ['pr', 'at']
# covvec: ['pr', 'at', 'ws', 'dp', 'sr', 'lr'] # all in tstoy04

h_size: 32 # 8,16,32,64 <= 32 generally good
o_size: 1 # 1
nb_layers: 1 # 1

lambda_LaplacianReg: 0.01 # 0.0, 0.01, 0.05
# ^ multiplies sum abs diff pred within each batch
len_reg: 10 # min(10, batch_len/4)
# ^ nb pred that are regularized in each batch, must be < batch_len

actout: 'ReLU' # 'ReLU', 'Softplus', 'Sigmoid'
# ^ 'ReLU' and 'Softplus' for tstoy04-tstoy06, 'Sigmoid' for tstoy07

torch_seed: 123 # torch.randn

maxepoch: 20 # 50, 100, 200, 500
step_ckpt: 10 # 10
# ^ print and record tr/va loss every maxepoch/step_ckpt epoch

loss: 'MAE' # 'MSE', 'MAE'
optim: 'RMSprop' # 'RMSprop', 'Adam', 'AdamW', 'RAdam'
learning_rate: 1e-2 # 1e-2 is good, 1e-1 better if scheduling
alphal2: 0.1 # L2 pen (weight decay) # 0.0, 0.5, 0.8
momentum: 0.8 # momentum in RMSprop # 0.0, 0.5

# run from /mydata/forestcast/william/WP3:
# python src/twdlstm/train.py LSTM_runs/configs/config_00.yaml > LSTM_runs/logs/log_trva_00.txt
# python src/twdlstm/cv.py LSTM_runs/configs/config_00.yaml > LSTM_runs/logs/log_cv_00.txt
# python src/twdlstm/test.py LSTM_runs/configs/config_00.yaml > LSTM_runs/logs/log_te_00.txt
